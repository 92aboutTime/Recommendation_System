## 추천시스템 평가 -  01. 어떤 추천이 좋은 추천일까 -  feat. 추천알고리즘 성능 평가

### 추천 알고리즘의 또 다른 면모, 필터버블(Filter BUbble)

* 사용자가 전체 정보를 볼 기회를 박탈당함
* 추천시스템이 고도화될 수록 취향에 맞는 정보만 제공받고, 나머지 정보는 알 수 없음
* 예) 뉴스 등 컨텐츠 중 성향과 맞지 않는 정보는 차단된다. -> 정보의 비대칭, 편향적
* 사용자간의 양극화 현상 등 사회적 문제로 이러질 수 있음



### 추천시스템의 성능을 확인하는 방법 -1

1. Business 또는 Service 관점
   * 추천시스템을 적용하기 전과 후에 따라 달라진 점 파악
   * 매출, 구독 등 실제 수익 향상 여부
   * Click Through Rate(CTR) 등 방문자의 행동 변화 여부
2. Technique과 Operation 관점
   * 다양성 : 추천하는 아이템 종류의 변화
     * 새로운 추천시스템을 적용하기 전과 후를 비교할 때, 검색, 추천되는 아이템의 종류가 더 다양해졌는지 여부
   * 참심함 : 사용자가 한번도 보지 못한 아이템 또는 뜻밖의 아이템이 추천되는지 여부
   * 관련성 : 사용자와 얼마나 관련이 있는지, 실제 구매로 이어졌는지 여부



### 추천시스템의 성능을 확인하는 방법 -2

1. A/B Testing
   * 마케팅과 Web 분석에서 주로 활용하는 실험 방법
   * A와 B 2가지 서로 변형된 방법을 사용하여 진행하는 대조 실험(controlled experiment)
   * 가설을 직관이 아닌 데이터 또는 결과로 증명하여 의사결정에 도움을 줄 수 있다.
2. A/B Testing 예시
   * 오바마 선거캠프 대선 홍보
   * 넷플릭스 홈페이지



### 추천시스템의 성능을 확인하는 방법 -3

1. Offline Evaluation
   * 추천알고리즘 구현에 사용한 데이터를 Train/Valid/Test로 나누어 평가
   * RMSE 등 정량적인 지표를 활용한 객관적인 평가 가능
   * 수집된 데이터를 바탕으로 평가가 이루어지므로, 실제 서비스 상황에서 다르게 적용될 수 있음
   * 다양한 추천알고리즘을 쉽고 빠르게 평가할 수 있음
2. Online Evaluation
   * 추천시스템이 적용된 플랫폼에서 실제 사용자의 피드백, 평점 등 활용
   * 수집할 수 있는 데이터의 한계가 있으나, 실제 사용자의 데이터이기 때문에 정확한 평가 가능
   * 수집한 데이터는 추천서비스 향상에 직접적인 도움을 줄 수 있음



## 추천시스템 평가 -  02. 추천시스템 평가하기 -  RMSE

__RMSE가 좋다고 무조건 좋은 시스템은 아니다.__

### Root Mean Square Error (RMSE)

* 평균 제곱근 편차
* 실제 값과 모델의 예측 값의 차이를 하나의 숫자로 나타낸다
* 예측 대상 값에 영향을 받는다 (Scale-dependent)
  * 같은 0.01의 에러값도 어떤 y_pred와 y_actual을 사용했느냐에 따라 다른 의미를 갖는다.
  * 1 ~ 10점, 1~ 100점 사이에서 평가했을 때, 같은 0.01이라도 다르다.
* 평점 등 prediction problem의 추천 성능을 평가할 때 사용하는 지표(metric)
* 제곱을 하여 더 큰 오차를 만들고, 제곱근(root)으로 원래 scale의 의미있는 숫자로 돌아감
* RMSE는 낮을 수록 추천 알고리즘의 성능이 더 좋다고 정량적으로 평가 가능
  * 성능이 좋다고 해서 꼭 좋은 추천을 하는 것은 아님
  * 1.2에서 0.9로 RMSE가 25% 향상됨을 나타냄
* 잔차(residual)의 제곱을 산술평균한 값의 제곱근 = 표준편차 = RMSE
  * 관측값들의 상호간 편차 = 관측값과 실제값 사이의 오차

>  추천시스템에는 정답이 없기 때문에 RMSE만을 통해서 성능을 판단해선 안된다. 
>
> 실제로 어떠한 예측을 했는지 관찰하고 실제 데이터와 비교분석하는 것이 중요하다.



## 추천시스템 평가 -  03. 추천시스템 평가하기 -  NDCG

### Normalized Discounted Cumulative Gain(NDCG)

https://ride-or-die.info/normalized-discounted-cumulative-gain/

* 랭킹 추천에 많이 사용되는 평가 지표(evaluation metric)
* 기존 정보검색(Information Retrieval)에서 많이 사용했던 지표
  * 어떤 검색어를 입력했을 때, 검색된 결과의 순서들이 내가 찾고자 하는 결과에 부합되는 순위가 맞는지를 평가하는 방식
  * 결과의 리스트에 내가 원하는 정보가 있는지 없는지 여부를 평가한다.
  * 원하는 정보의 순서도 평가한다.
* Top-N 랭킹 리스트를 만들과, 더 관심있거나 관련성 높은 아이템 포함 여부를 평가
* 순위에 가중치를 주고, 단순한 랭킹이 아닌 데이터의 성향을 반영하기 위한 평가 지표
* MAP(Mean Average Precision), Top K Precision/Recall 등 평가방법 보안
  * 정보 또는 정보검색에서 특정 아이템에 biased된 경우
    * 정보가 많이 알려졌거나 많이 노출된 아이템의 경우 bias를 가진다.
    * 평가된 적이 없고 사용된 적 없는 아이템의 경우도 Ranking에 포함된다면 문제가 될 수 있다.
    * 위의 두 경우를 보완하기 위해서 나온 것이 NDCG이다.
  * 이미 유명하고 잘 알려진 인기있는 아이템 또는 한 명의 사용자에 의해서 만들어진 랭킹 등 문제
* 가장 이상적인 랭킹(정답 랭킹)과 현재 점수를 활용한 랭킹사이의 점수를 cumulative하게 비교
* 1에 가까울수록 좋은 랭킹
* log로 normalization하여 순위가 낮을 수록 가중치를 감소
  * 1, 2등을 맞춘 추천시스템이 99, 100등을 맞춘 추천시스템보다 성능을 좋게 나타내기 위함
* 검색엔진, 영상, 음악 등 컨텐츠 랭킹 추천에서 주요 평가지표로 활용



### NDCG 구하는 법

###### 09:40

__CG__

* 상위 아이템 p개의 관련성을 합한 cumulative gain
* rel -> binary(관련여부) 또는 complex value(문제에 따라 세분화된 값)
* 상위 아이템 p개에 대해서 동일한 비중으로 합함.

__DCG__

* 개별 아이템의 관련성에 log normailzation을 적용함.
* 랭킹에 따라 비중을 discount해서 관련성을 계산
* 하위권 penalty 부여

__NDCG__

* 이상적인 DCG(ideal DCG)를 계산하고, 최종 NDCG를 계산함
* IDCGG는 전체 p개의 결과 중 가질 수 있는 가장 큰 값









